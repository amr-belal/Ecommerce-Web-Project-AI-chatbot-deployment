from modules.WeatherLoc import LoctWeatherAPI
import os


class Chatbot :
    def __init__(self):
        pass
    
    
    def gemeini_api(self ):
        pass 
    
    
    def Llama_model (self):
        pass 
    
    
    
    # last sprint in this model ==>  1- vectordata base  2- LLM model 3- RAG pipline
    # integrate in  themodel prompt the username ,location ,  weather ,keywords ,user message and build your prompt 
    # and then pass it to the LLM model
    # NOW use the  model Gemini 2,5 pro to get the response
    # and return the response 
    #if needed store the prompt inthedatabase for further use or for building recommendation sys  or any other purpose
    
    
    